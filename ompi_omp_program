#!/usr/bin/env python3
"""
Script to perform o3skiming on the o3as database.
"""
import argparse
import functools
import logging
import os
import subprocess
import sys
from pathlib import Path

import dask
import yaml
from environs import Env

# Initialize environment --------------------------------------------
env = Env()
env.read_env()

RUN_SKIMMING = env.bool("RUN_SKIMMING", default=True)
RUN_METADATA = env.bool("RUN_METADATA", default=True)
RUN_CFCHECKS = env.bool("RUN_CFCHECKS", default=True)

def set_verbosity(value):
    global VERBOSITY
    VERBOSITY = value
    logging.basicConfig(
        level=getattr(logging, VERBOSITY),
        format='%(asctime)s main ---- %(levelname)-8s %(message)s',
    )

def set_output(value):
    global OUTPUT
    OUTPUT = Path(value)

def set_sources(value):
    global SOURCES
    SOURCES = Path(value)

def set_source_file(value):
    global SOURCE_FILE
    SOURCE_FILE = Path(value)     


# Script arguments definition ---------------------------------------
parser = argparse.ArgumentParser(
    prog='PROG', description=__doc__,
    formatter_class=argparse.RawDescriptionHelpFormatter,
    epilog="See '<command> --help' to read about a specific sub-command.")
parser.add_argument(
    "-v", "--verbosity", type=str, default='INFO', 
    choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'],
    help="Sets the logging level (default: %(default)s)")
parser.add_argument(
    "-o", "--output", type=str, default='Skimmed',
    help="Output folder for skimmed files (default: %(default)s)")
parser.add_argument(
    "-s", "--sources", type=str, default='Sources',
    help="Sources folder for input paths (default: %(default)s)")
parser.add_argument(
    "--source_file", type=str, default='sources.yaml',
    help="Path to source file with skimming configurations")


# Script command actions --------------------------------------------
def run_command(
    verbosity, output, sources, source_file, **options
):
    # Common operations
    set_verbosity(verbosity)
    logging.info("Program start")
    logging.debug(f"Working directory:\n{os.getcwd()}")
    logging.debug(f"List directory:\n{os.listdir()}")
    set_output(output)
    logging.debug(f"Output dir files:\n{os.listdir(OUTPUT)}")
    set_sources(sources)
    logging.debug(f"Source dir files:\n{os.listdir(SOURCES)}")
    set_source_file(source_file)

    # Read source file
    logging.info("Reading source files %s", SOURCE_FILE)
    with open(SOURCE_FILE, 'r') as stream:
        models = yaml.safe_load(stream)
    logging.debug(f"Source file:\n{models}")

    # Define pool processes
    logging.info("Computing skimming pool of models")
    dask.compute(*[
        dask.delayed(worker_call)(model, **kwargs) 
        for model, kwargs in models.items()
    ])

    # End of program
    logging.info("End of program")


# Worker actions ----------------------------------------------------
def worker_call(model, source, operations=[], tco3_zm=None):
    logger = logging.getLogger(f"Skimming:{model}")
    output_folder = Path(f"{OUTPUT}/{model}")
    logger.info(f"Checking sources on directory:\n{output_folder}")
    eval_tco3(output_folder, **tco3_zm)
    logger.info(f"Skimming output on directory:\n{output_folder}")
    tco3_pm = skim_tco3(output_folder, operations, **tco3_zm) 
    logger.info(f"Saving metadata on directory:\n{output_folder}")
    metadata(output_folder, tco3_zm=tco3_pm) 


def eval_tco3(
    output_folder,  # Output location for the check file
    paths,  # Path with the CF netCDF files
    **kwargs,  # Unused arguments
):
    # Common operations
    output_file = f"{output_folder}/cfchecks_output.txt"
    os.makedirs(Path(output_folder), exist_ok=True)

    # Loading of DataArray and attributes
    paths = f"{SOURCES}/{paths}"
    call = f"cfchecks --version=auto {paths}"
    with open(output_file, "w") as f:
        subprocess.run(call, shell=True, stdout=f)

    # End of program
    return None


def skim_tco3(
    output_folder,  # Output location for the skimmed file
    operations, # Skimming operations to perform
    paths,      # Path with the CF netCDF files
    variable,   # Variable with tco3 data to skim
    file_name="tco3_zm.nc",  # Name of output file 
    **plot_metadata,  # Plot metadata for tco3_zm
):
    # Common operations
    output_file = f"{output_folder}/{file_name}"
    os.makedirs(Path(output_folder), exist_ok=True)

    # Loading of DataArray and attributes
    exec = f"skim_tco3 -v={VERBOSITY} -o={output_file} -n={variable}"
    operations = functools.reduce(lambda acc, x: acc + f" --{x}", operations, "")
    paths = f"{SOURCES}/{paths}"
    call = f"{exec} {operations} {paths}"
    if RUN_SKIMMING:
        subprocess.run(call, shell=True, check=True)

    # End of program
    return plot_metadata


def metadata(
    output_folder,  # Output location for the skimmed file
    file_name="metadata.yaml",  # Name of output file
    **metadata,  # Metadata to save on output folder
):
    # Common operations
    output_file = f"{output_folder}/{file_name}"
    os.makedirs(Path(output_folder), exist_ok=True)

    # Saving metadata in model output
    if RUN_METADATA:
        with open(output_file, 'w') as outfile:
            yaml.dump(metadata, outfile, default_flow_style=False)

    # End of program
    return None


# Main call ---------------------------------------------------------
if __name__ == '__main__':
    args = parser.parse_args()
    # try:
    run_command(**vars(args))
    sys.exit(0)  # Shell return 0 == success
